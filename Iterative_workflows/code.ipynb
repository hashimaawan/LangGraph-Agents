{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d48a3b5",
   "metadata": {},
   "source": [
    "## Posting Agent -> that improves over iterations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c493824",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import TypedDict, Literal\n",
    "import operator\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcb50da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In real applications, you would define the model that is good for particular task.\n",
    "\n",
    "# Create Ollama LLaMA model\n",
    "generator_llm = ChatOllama(\n",
    "    model=\"llama3.2:1b\",  # <-- or \"llama3\", or any valid name from `ollama list`\n",
    "    base_url=\"http://localhost:11434\"\n",
    ")\n",
    "\n",
    "evaluator_llm = ChatOllama(\n",
    "    model=\"llama3.2:1b\",  # <-- or \"llama3\", or any valid name from `ollama list`\n",
    "    base_url=\"http://localhost:11434\"\n",
    ")\n",
    "\n",
    "optimizer_llm = ChatOllama(\n",
    "    model=\"llama3.2:1b\",  # <-- or \"llama3\", or any valid name from `ollama list`\n",
    "    base_url=\"http://localhost:11434\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f047dc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the state graph for iterative workflows\n",
    "# Platform target is Twitter abd the task is to generate a tweet\n",
    "class TweetState(TypedDict):\n",
    "\n",
    "    topic: str\n",
    "    tweet: str\n",
    "    feedback: str\n",
    "    evaluation: Literal[\"approved\", \"rejected\"]\n",
    "    iteration: int\n",
    "    max_iterations: int\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918926f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tweet(state: TweetState) -> TweetState:\n",
    "    \"\"\"Generate a tweet based on the topic.\"\"\"\n",
    "    response = generator_llm.invoke(\n",
    "        f\"Generate a tweet about {state['topic']}\"\n",
    "    )\n",
    "    state['tweet'] = response.content.strip()\n",
    "    return state\n",
    "\n",
    "\n",
    "def evaluate_tweet(state: TweetState) -> TweetState:\n",
    "    \"\"\"Evaluate the tweet and provide feedback.\"\"\"\n",
    "    response = evaluator_llm.invoke(\n",
    "        f\"Evaluate this tweet: {state['tweet']}. Provide feedback.\"\n",
    "    )\n",
    "    state['feedback'] = response.content.strip()\n",
    "    \n",
    "\n",
    "    if \"good\" in state['feedback'].lower():\n",
    "        state['evaluation'] = \"approved\"\n",
    "    else:\n",
    "        state['evaluation'] = \"rejected\"\n",
    "    \n",
    "    return state\n",
    "\n",
    "def optimize_tweet(state: TweetState) -> TweetState:\n",
    "    \"\"\"Optimize the tweet based on feedback.\"\"\"\n",
    "    if state['evaluation'] == \"rejected\":\n",
    "        response = optimizer_llm.invoke(\n",
    "            f\"Improve this tweet: {state['tweet']}. Feedback: {state['feedback']}\"\n",
    "        )\n",
    "        state['tweet'] = response.content.strip()\n",
    "    \n",
    "\n",
    "    state['iteration'] += 1\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "402ec3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Tweet: Here's a revised version of the tweet:\n",
      "\n",
      "\"It's time to think critically about the potential consequences of AI on our workforce and our future. As researchers at Google found, up to 800 million jobs could be lost worldwide by 2030 due to automation alone. It's crucial we consider how AI will shape our economy, education systems, and social structures. We need to engage in discussions that take into account the potential consequences of this technology #ArtificialIntelligence #SocietalImpact\"\n",
      "\n",
      "I made several changes to improve the tweet:\n",
      "\n",
      "* Started with a specific quote from researchers, adding credibility and depth to the argument.\n",
      "* Replaced \"Let's have open conversations about...\" with a more nuanced expression that encourages thoughtful discussion (\"think critically\").\n",
      "* Used more relatable language by focusing on the human impact of AI (e.g., \"our workforce\", \"our future\") instead of just mentioning job displacement.\n",
      "* Added some context and background information to help readers understand the broader significance of the argument (e.g., specific research findings, potential consequences).\n",
      "* Emphasized the importance of responsible development and implementation, highlighting the need for a thoughtful discussion about the implications of AI.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Define workflow\n",
    "workflow = StateGraph(TweetState)\n",
    "\n",
    "workflow.add_node(\"generate_tweet\", generate_tweet)\n",
    "workflow.add_node(\"evaluate_tweet\", evaluate_tweet)\n",
    "workflow.add_node(\"optimize_tweet\", optimize_tweet)\n",
    "\n",
    "# Normal edges\n",
    "workflow.add_edge(START, \"generate_tweet\")\n",
    "workflow.add_edge(\"generate_tweet\", \"evaluate_tweet\")\n",
    "\n",
    "# Conditional edges\n",
    "workflow.add_conditional_edges(\n",
    "    \"evaluate_tweet\",\n",
    "    lambda state: \"approved\" if state[\"evaluation\"] == \"approved\" else \"rejected\",\n",
    "    {\n",
    "        \"approved\": END,\n",
    "        \"rejected\": \"optimize_tweet\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"optimize_tweet\",\n",
    "    lambda state: \"continue\" if state[\"iteration\"] < state[\"max_iterations\"] else \"stop\",\n",
    "    {\n",
    "        \"continue\": \"evaluate_tweet\",\n",
    "        \"stop\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# Extra safeguard\n",
    "workflow.add_conditional_edges(\n",
    "    START,\n",
    "    lambda state: \"stop\" if state[\"max_iterations\"] <= 0 else \"go\",\n",
    "    {\n",
    "        \"stop\": END,\n",
    "        \"go\": \"generate_tweet\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Compile graph\n",
    "app = workflow.compile()\n",
    "\n",
    "# Example usage\n",
    "initial_state = TweetState(\n",
    "    topic=\"AI and its impact on society\",\n",
    "    tweet=\"\",\n",
    "    feedback=\"\",\n",
    "    evaluation=\"rejected\",\n",
    "    iteration=0,\n",
    "    max_iterations=3\n",
    ")\n",
    "\n",
    "final_state = app.invoke(initial_state)\n",
    "print(\"Final Tweet:\", final_state[\"tweet\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7b7e06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
